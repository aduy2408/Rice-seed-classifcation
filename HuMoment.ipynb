{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import mahotas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@1.111] global loadsave.cpp:268 findDecoder imread_('/home/duyle/Rice_photos/BC-15/positive/DSC6771_idx1.png'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) /io/opencv/modules/imgproc/src/color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(image_path)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Convert to grayscale\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2GRAY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Apply Gaussian Blur to reduce noise\u001b[39;00m\n\u001b[1;32m      9\u001b[0m blur \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mGaussianBlur(image, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), \u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.11.0) /io/opencv/modules/imgproc/src/color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Load the image\n",
    "image_path = \"/home/duyle/Rice_photos/BC-15/positive/DSC6771_idx1.png\"  # Update with your image path\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Convert to grayscale\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply Gaussian Blur to reduce noise\n",
    "blur = cv2.GaussianBlur(image, (3, 3), 0)\n",
    "threshold, new_img = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "contours, _ = cv2.findContours(new_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "\n",
    "    # Compute Hu Moments\n",
    "moments = cv2.moments(contour)\n",
    "hu_moments = cv2.HuMoments(moments)\n",
    "\n",
    "# Apply log transformation with a small epsilon to prevent log(0) issues\n",
    "hu_moments = -np.sign(hu_moments) * np.log10(np.abs(hu_moments) + 1e-10)\n",
    "\n",
    "\n",
    "print(hu_moments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import convolve\n",
    "def extract_edge_histogram_features(image):\n",
    "    \"\"\"\n",
    "    Compute a simplified edge histogram descriptor (EDH) from the image.\n",
    "    The function applies five convolution kernels corresponding to different edge orientations.\n",
    "    \"\"\"\n",
    "    # Convert to grayscale if necessary.\n",
    "    if len(image.shape) > 2:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = image.copy()\n",
    "    \n",
    "    # Define convolution kernels for five edge types.\n",
    "    kernels = {\n",
    "        \"vertical\": np.array([[-1,  2, -1],\n",
    "                              [-1,  2, -1],\n",
    "                              [-1,  2, -1]], dtype=np.float32),\n",
    "        \"horizontal\": np.array([[-1, -1, -1],\n",
    "                                [ 2,  2,  2],\n",
    "                                [-1, -1, -1]], dtype=np.float32),\n",
    "        \"diag_45\": np.array([[-1, -1,  2],\n",
    "                             [-1,  2, -1],\n",
    "                             [ 2, -1, -1]], dtype=np.float32),\n",
    "        \"diag_135\": np.array([[ 2, -1, -1],\n",
    "                              [-1,  2, -1],\n",
    "                              [-1, -1,  2]], dtype=np.float32),\n",
    "        # A non-directional (Laplacian-like) kernel.\n",
    "        \"non_directional\": np.array([[1,  1,  1],\n",
    "                                     [1, -8,  1],\n",
    "                                     [1,  1,  1]], dtype=np.float32)\n",
    "    }\n",
    "    \n",
    "    features = {}\n",
    "    total_energy = 0.0\n",
    "    \n",
    "    # Convolve the image with each kernel and compute the energy.\n",
    "    for key, kernel in kernels.items():\n",
    "        response = convolve(gray.astype(np.float32), kernel, mode=\"reflect\")\n",
    "        energy = np.sum(np.abs(response))\n",
    "        features[f\"edge_energy_{key}\"] = energy\n",
    "        total_energy += energy\n",
    "    \n",
    "    # Normalize to form a histogram (if total energy > 0).\n",
    "    if total_energy > 0:\n",
    "        for key in list(features.keys()):\n",
    "            features[key] /= total_energy\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'edge_energy_vertical': np.float32(0.11537549),\n",
       " 'edge_energy_horizontal': np.float32(0.246982),\n",
       " 'edge_energy_diag_45': np.float32(0.16055416),\n",
       " 'edge_energy_diag_135': np.float32(0.15892461),\n",
       " 'edge_energy_non_directional': np.float32(0.31816378)}"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_edge_histogram_features(cv2.imread('/home/duyle/Rice_photos/BC-15/BC-15/DSC7436_idx70.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_structure_descriptor(image, grid_size=(8, 8), bins=32):\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    \n",
    "    height, width = hsv_image.shape[:2]\n",
    "    cell_h, cell_w = height // grid_size[0], width // grid_size[1]\n",
    "\n",
    "    \n",
    "    hist_bins = [bins] \n",
    "\n",
    "    \n",
    "    csd = []\n",
    "\n",
    "    for row in range(grid_size[0]):\n",
    "        for col in range(grid_size[1]):\n",
    "            x_start, y_start = col * cell_w, row * cell_h\n",
    "            x_end, y_end = x_start + cell_w, y_start + cell_h\n",
    "            cell = hsv_image[y_start:y_end, x_start:x_end]\n",
    "\n",
    "            hist = cv2.calcHist([cell], [0], None, hist_bins, [0, 180])\n",
    "            hist = hist.flatten() \n",
    "            hist = hist / hist.sum() if hist.sum() != 0 else hist\n",
    "\n",
    "            csd.extend(hist)\n",
    "\n",
    "    return {f\"csd_{i}\":csd[i] for i in range(len(csd))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_density_feature(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(gray, 100, 200)  # Edge detection\n",
    "    edge_density = np.sum(edges) / (image.shape[0] * image.shape[1])  # Normalize by image size\n",
    "    return edge_density\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"/home/duyle/Documents/AIL/rice_seed/BC-15/negative/DSC6543_idx5.png\"  # Update with your image path\n",
    "image = cv2.imread(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyefd import elliptic_fourier_descriptors, normalize_efd, reconstruct_contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_efd_features(image, n_harmonics=10):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(image, (3, 3), 0)\n",
    "    threshold, new_img = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    \n",
    "    area = np.count_nonzero(new_img)\n",
    "    contours, _ = cv2.findContours(new_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contour = max(contours, key=cv2.contourArea)\n",
    "    # Preprocess to get contour\n",
    "\n",
    "    \n",
    "    # Convert OpenCV contour format to the format expected by PyEFD\n",
    "    contour_array = contour.reshape(-1, 2)\n",
    "    \n",
    "    # Calculate EFD coefficients\n",
    "    coeffs = elliptic_fourier_descriptors(contour_array, order=n_harmonics, normalize=True)\n",
    "    \n",
    "    # Flatten the coefficients into a feature vector\n",
    "    features = coeffs.flatten()\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.00000000e+00, -1.63849546e-17, -2.23109318e-16, -3.09916031e-01,\n",
       "        2.95931488e-02, -1.59992690e-02,  2.73633083e-02, -2.05992298e-02,\n",
       "        6.22834872e-02, -9.88907731e-04,  3.33573312e-02, -2.21300023e-02,\n",
       "        1.78338960e-02, -1.67408307e-02, -6.67361812e-04, -8.68330419e-03,\n",
       "        1.33569045e-02, -4.97332668e-03,  1.81737743e-02,  3.95266753e-03,\n",
       "        6.58239860e-03, -1.89787758e-02, -6.03084834e-03,  7.47268487e-04,\n",
       "        5.45950677e-03,  1.60588736e-03,  1.54213332e-02, -1.07541685e-03,\n",
       "        4.03094792e-03, -1.49563242e-02, -1.15260525e-02,  7.01534211e-03,\n",
       "        5.25896729e-03,  2.14805111e-03,  8.89432096e-03, -3.24629155e-03,\n",
       "        2.68091917e-03, -1.21926740e-02, -6.92303607e-03,  1.52820512e-03])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_efd_features(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(image, (3, 3), 0)\n",
    "    threshold, new_img = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    \n",
    "    area = np.count_nonzero(new_img)\n",
    "    contours, _ = cv2.findContours(new_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contour = max(contours, key=cv2.contourArea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_css_features_fixed(image, num_features=20):\n",
    "    \"\"\"Extract Curvature Scale Space features from rice seed contour\"\"\"\n",
    "    # Preprocess image\n",
    "    if len(image.shape) > 2:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(image, (3, 3), 0)\n",
    "    _, binary = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contour = max(contours, key=cv2.contourArea)\n",
    "    \n",
    "    # Convert to numpy array\n",
    "    contour_array = contour.reshape(-1, 2)\n",
    "    \n",
    "    # Ensure enough points for analysis\n",
    "    if len(contour_array) < 50:\n",
    "        # Interpolate to get more points\n",
    "        t = np.arange(len(contour_array))\n",
    "        ti = np.linspace(0, t[-1], 100)\n",
    "        x = np.interp(ti, t, contour_array[:, 0])\n",
    "        y = np.interp(ti, t, contour_array[:, 1])\n",
    "        contour_array = np.column_stack((x, y))\n",
    "    \n",
    "    # Initialize features\n",
    "    features = {}\n",
    "    \n",
    "    # Define scales for CSS\n",
    "    scales = np.linspace(1, 10, num_features)\n",
    "    \n",
    "    # For each scale, smooth the contour first, then calculate curvature\n",
    "    for i, sigma in enumerate(scales):\n",
    "        # Get x and y coordinates\n",
    "        x = contour_array[:, 0]\n",
    "        y = contour_array[:, 1]\n",
    "        \n",
    "        # Create kernel size based on sigma (must be odd)\n",
    "        ksize = int(2 * np.ceil(3 * sigma) + 1)\n",
    "        \n",
    "        # Use 1D Gaussian filter from scipy instead of OpenCV\n",
    "        from scipy.ndimage import gaussian_filter1d\n",
    "        x_smooth = gaussian_filter1d(x, sigma)\n",
    "        y_smooth = gaussian_filter1d(y, sigma)\n",
    "        \n",
    "        # Calculate derivatives of the smoothed contour\n",
    "        dx = np.gradient(x_smooth)\n",
    "        dy = np.gradient(y_smooth)\n",
    "        ddx = np.gradient(dx)\n",
    "        ddy = np.gradient(dy)\n",
    "        \n",
    "        # Calculate curvature\n",
    "        curvature = np.abs((dx * ddy - dy * ddx) / (dx**2 + dy**2)**(3/2))\n",
    "        \n",
    "        # Replace NaN values (from division by zero) with zeros\n",
    "        curvature = np.nan_to_num(curvature)\n",
    "        \n",
    "        # Find zero crossings in curvature\n",
    "        # For curvature, look for local maxima (peaks) which are more meaningful\n",
    "        peaks = np.where((curvature[1:-1] > curvature[:-2]) & \n",
    "                         (curvature[1:-1] > curvature[2:]))[0] + 1\n",
    "        \n",
    "        # Store features\n",
    "        features[f'css_peaks_scale_{i+1}'] = len(peaks)\n",
    "        features[f'css_max_curve_scale_{i+1}'] = np.max(curvature)\n",
    "        features[f'css_mean_curve_scale_{i+1}'] = np.mean(curvature)\n",
    "        features[f'css_std_curve_scale_{i+1}'] = np.std(curvature)\n",
    "    \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_36574/1348683780.py:52: RuntimeWarning: invalid value encountered in divide\n",
      "  curvature = np.abs((dx * ddy - dy * ddx) / (dx**2 + dy**2)**(3/2))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'css_peaks_scale_1': 45,\n",
       " 'css_max_curve_scale_1': 3.0,\n",
       " 'css_mean_curve_scale_1': 0.08494810693334814,\n",
       " 'css_std_curve_scale_1': 0.24865859208507202,\n",
       " 'css_peaks_scale_2': 49,\n",
       " 'css_max_curve_scale_2': 1.0,\n",
       " 'css_mean_curve_scale_2': 0.08182609135074428,\n",
       " 'css_std_curve_scale_2': 0.16796246148587984,\n",
       " 'css_peaks_scale_3': 52,\n",
       " 'css_max_curve_scale_3': 1.0,\n",
       " 'css_mean_curve_scale_3': 0.07335109628611651,\n",
       " 'css_std_curve_scale_3': 0.1597841751755472,\n",
       " 'css_peaks_scale_4': 52,\n",
       " 'css_max_curve_scale_4': 1.0,\n",
       " 'css_mean_curve_scale_4': 0.07929466889385732,\n",
       " 'css_std_curve_scale_4': 0.1862249260889533,\n",
       " 'css_peaks_scale_5': 52,\n",
       " 'css_max_curve_scale_5': 2.0,\n",
       " 'css_mean_curve_scale_5': 0.07948047108917687,\n",
       " 'css_std_curve_scale_5': 0.20754853730235906,\n",
       " 'css_peaks_scale_6': 54,\n",
       " 'css_max_curve_scale_6': 1.0,\n",
       " 'css_mean_curve_scale_6': 0.07352994255542572,\n",
       " 'css_std_curve_scale_6': 0.16529106488767908,\n",
       " 'css_peaks_scale_7': 54,\n",
       " 'css_max_curve_scale_7': 2.0,\n",
       " 'css_mean_curve_scale_7': 0.07046107172045206,\n",
       " 'css_std_curve_scale_7': 0.19272056070709642,\n",
       " 'css_peaks_scale_8': 52,\n",
       " 'css_max_curve_scale_8': 1.0,\n",
       " 'css_mean_curve_scale_8': 0.06289366784385447,\n",
       " 'css_std_curve_scale_8': 0.16078014608453622,\n",
       " 'css_peaks_scale_9': 54,\n",
       " 'css_max_curve_scale_9': 1.0606601717798212,\n",
       " 'css_mean_curve_scale_9': 0.07282351297459422,\n",
       " 'css_std_curve_scale_9': 0.15380827193509308,\n",
       " 'css_peaks_scale_10': 57,\n",
       " 'css_max_curve_scale_10': 1.0,\n",
       " 'css_mean_curve_scale_10': 0.07768876837631014,\n",
       " 'css_std_curve_scale_10': 0.1683976936507131}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_css_features_fixed(image, num_features=10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.16",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
